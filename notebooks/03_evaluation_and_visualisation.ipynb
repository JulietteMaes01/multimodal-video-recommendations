{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4cf6b7",
   "metadata": {},
   "source": [
    "# Evaluation of video CBRS\n",
    "\n",
    "##### Evaluation of E2E models an dintelligent plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f74fa52",
   "metadata": {},
   "source": [
    "****\n",
    "* pair-cosine\n",
    "* pair-euclidean\n",
    "* triplet-cosine\n",
    "* tirplet-euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36f225",
   "metadata": {},
   "source": [
    "## Evaluation Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16205e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete.\n"
     ]
    }
   ],
   "source": [
    "# Standard Library Imports\n",
    "import os, pickle, re, io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Dict, List, Set, Tuple, Any\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import botocore\n",
    "\n",
    "# --- GLOBAL CONSTANTS ---\n",
    "S3_BUCKET_NAME = \"md-data-content-recommendation\"\n",
    "RATINGS_BENCHMARK_KEY = 'evaluation/ratings_13919_filtered.csv'\n",
    "K_VALUES = [1, 3, 5, 10]\n",
    "FINAL_RESULTS_KEY = \"comparison_evaluation/final_all_models_per_epoch_results.csv\"\n",
    "\n",
    "print(\"Setup Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1de9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle s3\n",
    "def load_data_from_s3(bucket: str, key: str) -> Any:\n",
    "    \"\"\"Load data from S3 bucket.\"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    if key.endswith('.pkl'):\n",
    "        data = pickle.loads(response['Body'].read())\n",
    "    elif key.endswith('.csv'):\n",
    "        data = pd.read_csv(response['Body'])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {key}\")\n",
    "    print(f\"Successfully loaded data from s3://{bucket}/{key}\")\n",
    "    return data\n",
    "\n",
    "def save_data_to_s3(data: Any, bucket: str, key: str) -> None:\n",
    "    \"\"\"Save data to S3 bucket.\"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        csv_data = data.to_csv(index=False).encode('utf-8')\n",
    "        s3_client.put_object(\n",
    "            Body=csv_data,\n",
    "            Bucket=bucket,\n",
    "            Key=key\n",
    "        )\n",
    "    else:\n",
    "        s3_client.put_object(\n",
    "            Body=pickle.dumps(data),\n",
    "            Bucket=bucket,\n",
    "            Key=key\n",
    "        )\n",
    "    print(f\"Successfully saved data to s3://{bucket}/{key}\")\n",
    "    \n",
    "def load_feature_embeddings(s3_bucket, key):\n",
    "    \"\"\"Load feature embeddings from S3.\"\"\"\n",
    "    print(\"Loading feature embeddings 1...\")\n",
    "    data = load_data_from_s3(s3_bucket, key)\n",
    "    features = np.array(data[\"features\"]) if not isinstance(data[\"features\"], np.ndarray) else data[\"features\"]\n",
    "    return features, data[\"trailer_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf335432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_user_item_data(ratings_df: pd.DataFrame, sample_size: int = None) -> Tuple[Dict[str, Set[str]], Dict[str, Dict[str, float]]]:\n",
    "    \"\"\"\n",
    "    Prepare user-item interaction data for evaluation.\n",
    "    Returns:\n",
    "        - user_items: Dict mapping userId to a set of relevant items (binary_rating=1)\n",
    "        - user_item_ratings: Dict mapping userId to a dict of itemId -> rating\n",
    "    \"\"\"\n",
    "    print(\"Preparing user-item interaction data...\")\n",
    "    \n",
    "    # Map for relevant items (binary_rating=1)\n",
    "    user_items = defaultdict(set)\n",
    "    # Map for all ratings\n",
    "    user_item_ratings = defaultdict(dict)\n",
    "    \n",
    "    # If sample_size is provided, limit the number of users\n",
    "    if sample_size:\n",
    "        # Get unique user IDs\n",
    "        unique_users = ratings_df['userId'].unique()\n",
    "        if len(unique_users) > sample_size:\n",
    "            # Sample a subset of users\n",
    "            sampled_users = np.random.choice(unique_users, sample_size, replace=False)\n",
    "            ratings_df = ratings_df[ratings_df['userId'].isin(sampled_users)]\n",
    "            print(f\"Sampled {sample_size} users out of {len(unique_users)} for faster evaluation\")\n",
    "    \n",
    "    for _, row in tqdm(ratings_df.iterrows(), total=len(ratings_df)):\n",
    "        user_id = str(row['userId'])\n",
    "        movie_id = str(row['movieId'])\n",
    "        rating = float(row['rating'])\n",
    "        binary_rating = int(row['binary_rating'])\n",
    "        \n",
    "        # Add to relevant items if binary_rating is 1\n",
    "        if binary_rating == 1:\n",
    "            user_items[user_id].add(movie_id)\n",
    "        \n",
    "        # Store the rating\n",
    "        user_item_ratings[user_id][movie_id] = rating\n",
    "    \n",
    "    print(f\"Processed {len(user_items)} users with relevant items\")\n",
    "    return user_items, user_item_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40778bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_movie_id_from_trailer_id(trailer_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract a movie ID from a trailer ID string.\n",
    "    This function tries several methods to extract what might be a movie ID.\n",
    "    \"\"\"\n",
    "    # Method 1: Try to extract digits from the trailer ID\n",
    "    digits = re.findall(r'\\d+', trailer_id)\n",
    "    if digits:\n",
    "        return digits[0]\n",
    "    \n",
    "    # Method 2: Use the trailer ID as is\n",
    "    return trailer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10caa0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_improved_trailer_to_movie_mapping(recommendations, ratings_df):\n",
    "    \"\"\"\n",
    "    Create a more robust mapping from trailer_ids to movieIds.\n",
    "    This uses multiple approaches including substring matching and\n",
    "    filtering to find potential matches.\n",
    "    \"\"\"\n",
    "    trailer_to_movie = {}\n",
    "    movie_ids = set(str(id) for id in ratings_df['movieId'].unique())\n",
    "    \n",
    "    # For each trailer ID in recommendations\n",
    "    for trailer_id in recommendations.keys():\n",
    "        # Method 1: Direct match (if trailer_id exists directly in movie_ids)\n",
    "        if trailer_id in movie_ids:\n",
    "            trailer_to_movie[trailer_id] = trailer_id\n",
    "            continue\n",
    "            \n",
    "        # Method 2: Extract digits and check if they match any movie ID\n",
    "        digits = re.findall(r'\\d+', trailer_id)\n",
    "        for digit in digits:\n",
    "            if digit in movie_ids:\n",
    "                trailer_to_movie[trailer_id] = digit\n",
    "                break\n",
    "                \n",
    "        # Method 3: Try to find movie ID that is a substring of trailer_id\n",
    "        for movie_id in movie_ids:\n",
    "            if movie_id in trailer_id:\n",
    "                trailer_to_movie[trailer_id] = movie_id\n",
    "                break\n",
    "                \n",
    "    print(f\"Created mapping for {len(trailer_to_movie)} trailer IDs to movie IDs\")\n",
    "    \n",
    "    # Print examples to help debug\n",
    "    examples = list(trailer_to_movie.items())[:5]\n",
    "    print(\"Mapping examples (trailer_id -> movie_id):\")\n",
    "    for trailer_id, movie_id in examples:\n",
    "        print(f\"  {trailer_id} -> {movie_id}\")\n",
    "    \n",
    "    # Also create reverse mapping\n",
    "    movie_to_trailer = {}\n",
    "    for trailer_id, movie_id in trailer_to_movie.items():\n",
    "        if movie_id not in movie_to_trailer:\n",
    "            movie_to_trailer[movie_id] = trailer_id\n",
    "    \n",
    "    print(f\"Created reverse mapping for {len(movie_to_trailer)} movie IDs to trailer IDs\")\n",
    "    \n",
    "    return trailer_to_movie, movie_to_trailer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5638e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_id_mapping(ratings_df, recommendations, trailer_to_movie):\n",
    "    # Get all unique movie IDs from ratings\n",
    "    rating_movie_ids = set(str(id) for id in ratings_df['movieId'].unique())\n",
    "    \n",
    "    mapped_movie_ids = set(trailer_to_movie.values())\n",
    "    \n",
    "    # Check overlap\n",
    "    overlap = rating_movie_ids.intersection(mapped_movie_ids)\n",
    "    \n",
    "    print(f\"Unique movie IDs in ratings: {len(rating_movie_ids)}\")\n",
    "    print(f\"Unique movie IDs from trailer mapping: {len(mapped_movie_ids)}\")\n",
    "    print(f\"Overlap between ratings and recommendations: {len(overlap)}\")\n",
    "    \n",
    "    # Print some examples for debugging\n",
    "    print(\"Sample movie IDs from ratings:\", list(rating_movie_ids)[:5])\n",
    "    print(\"Sample movie IDs from trailer mapping:\", list(mapped_movie_ids)[:5])\n",
    "    \n",
    "    return overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b06551",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaf4e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended_items: List[str], relevant_items: Set[str], k: int) -> float:\n",
    "    \"\"\"Calculate precision@k metric.\"\"\"\n",
    "    if k == 0 or len(recommended_items) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Take only the first k recommendations\n",
    "    recommended_k = recommended_items[:k]\n",
    "    # Count the number of relevant items in the recommendations\n",
    "    num_relevant = sum(1 for item in recommended_k if item in relevant_items)\n",
    "    \n",
    "    return num_relevant / min(k, len(recommended_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b50afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(recommended_items: List[str], relevant_items: Set[str], k: int) -> float:\n",
    "    \"\"\"Calculate recall@k metric.\"\"\"\n",
    "    if len(relevant_items) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Take only the first k recommendations\n",
    "    recommended_k = recommended_items[:k]\n",
    "    # Count the number of relevant items in the recommendations\n",
    "    num_relevant = sum(1 for item in recommended_k if item in relevant_items)\n",
    "    \n",
    "    return num_relevant / len(relevant_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e32f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate_at_k(recommended_items: List[str], relevant_items: Set[str], k: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate hit rate@k metric.\n",
    "    Hit rate is 1 if at least one relevant item is in the top-k recommendations, 0 otherwise.\n",
    "    \"\"\"\n",
    "    # Take only the first k recommendations\n",
    "    recommended_k = recommended_items[:k]\n",
    "    # Check if any recommended item is relevant\n",
    "    for item in recommended_k:\n",
    "        if item in relevant_items:\n",
    "            return 1.0\n",
    "    \n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d1bcafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(recommended_items: List[str], item_ratings: Dict[str, float], k: int) -> float:\n",
    "    \"\"\"Calculate Discounted Cumulative Gain at k.\"\"\"\n",
    "    if k == 0 or len(recommended_items) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Take only the first k recommendations\n",
    "    recommended_k = recommended_items[:k]\n",
    "    \n",
    "    dcg = 0\n",
    "    for i, item in enumerate(recommended_k):\n",
    "        if item in item_ratings:\n",
    "            # Use the actual rating as relevance score\n",
    "            rel = item_ratings[item]\n",
    "            # DCG formula: (2^rel - 1) / log2(i+2)\n",
    "            dcg += (2 ** rel - 1) / np.log2(i + 2)\n",
    "    \n",
    "    return dcg\n",
    "\n",
    "def idcg_at_k(item_ratings: Dict[str, float], k: int) -> float:\n",
    "    \"\"\"Calculate Ideal Discounted Cumulative Gain at k.\"\"\"\n",
    "    if k == 0 or len(item_ratings) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Sort ratings in descending order\n",
    "    sorted_ratings = sorted(item_ratings.values(), reverse=True)\n",
    "    # Take only the first k ratings (or all if less than k)\n",
    "    relevant_ratings = sorted_ratings[:min(k, len(sorted_ratings))]\n",
    "    \n",
    "    idcg = 0\n",
    "    for i, rel in enumerate(relevant_ratings):\n",
    "        # IDCG formula: same as DCG but with optimal ordering\n",
    "        idcg += (2 ** rel - 1) / np.log2(i + 2)\n",
    "    \n",
    "    return idcg\n",
    "\n",
    "def ndcg_at_k(recommended_items: List[str], item_ratings: Dict[str, float], k: int) -> float:\n",
    "    \"\"\"Calculate Normalized Discounted Cumulative Gain at k.\"\"\"\n",
    "    idcg = idcg_at_k(item_ratings, k)\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    dcg = dcg_at_k(recommended_items, item_ratings, k)\n",
    "    return dcg / idcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae264bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_reciprocal_rank(recommended_items: List[str], relevant_items: Set[str], k: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Mean Reciprocal Rank (MRR) for a list of recommendations.\n",
    "    \n",
    "    MRR measures where the first relevant item appears in the recommendation list.\n",
    "    For each query (user/item), the reciprocal rank is the inverse of the position \n",
    "    of the first relevant item in the results.\n",
    "    \n",
    "    Parameters:\n",
    "    recommended_items: List of recommended item IDs\n",
    "    relevant_items: Set of relevant item IDs\n",
    "    k: Number of recommendations to consider\n",
    "    \n",
    "    Returns:\n",
    "    float: MRR score (0 if no relevant items found)\n",
    "    \"\"\"\n",
    "    if not relevant_items or not recommended_items:\n",
    "        return 0.0\n",
    "    \n",
    "    # Consider only top-k recommendations\n",
    "    rec_items = recommended_items[:k]\n",
    "    \n",
    "    # Find the first relevant item\n",
    "    for i, item in enumerate(rec_items):\n",
    "        if item in relevant_items:\n",
    "            # Return reciprocal rank (1-based indexing)\n",
    "            return 1.0 / (i + 1)\n",
    "    \n",
    "    # No relevant items found\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f964f135",
   "metadata": {},
   "source": [
    "### Do actual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ece57ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_evaluation(recommendations: Dict[str, List[Dict[str, Any]]], \n",
    "                          user_items: Dict[str, Set[str]],\n",
    "                          user_item_ratings: Dict[str, Dict[str, float]],\n",
    "                          trailer_to_movie: Dict[str, str],\n",
    "                          k_values: List[int]) -> Dict[str, Dict[int, float]]:\n",
    "    \"\"\"\n",
    "    Evaluate recommendations using an item-based approach.\n",
    "    For each movie that users have rated, evaluate the recommendations for that movie.\n",
    "    \"\"\"\n",
    "    print(\"Performing item-based evaluation...\")\n",
    "    \n",
    "    # Create an inverse mapping from movie IDs to trailer IDs\n",
    "    movie_to_trailer = {movie_id: trailer_id for trailer_id, movie_id in trailer_to_movie.items()}\n",
    "    \n",
    "    # Initialize metrics\n",
    "    metrics = {\n",
    "        'precision': {k: 0.0 for k in k_values},\n",
    "        'recall': {k: 0.0 for k in k_values},\n",
    "        'hit_rate': {k: 0.0 for k in k_values},\n",
    "        'ndcg': {k: 0.0 for k in k_values},\n",
    "        'MRR': {k: 0.0 for k in k_values}\n",
    "    }\n",
    "    \n",
    "    # Track the number of evaluated items\n",
    "    evaluated_items = 0\n",
    "    \n",
    "    # Create a set of all rated movie IDs\n",
    "    all_rated_movies = set()\n",
    "    for user_ratings in user_item_ratings.values():\n",
    "        all_rated_movies.update(user_ratings.keys())\n",
    "    \n",
    "    print(f\"Found {len(all_rated_movies)} unique rated movies\")\n",
    "    \n",
    "    # For each movie that has been rated\n",
    "    for movie_id in tqdm(all_rated_movies, desc=\"Evaluating items\"):\n",
    "        # Find the corresponding trailer ID\n",
    "        trailer_id = movie_to_trailer.get(movie_id)\n",
    "        \n",
    "        # Skip if we don't have recommendations for this movie\n",
    "        if not trailer_id or trailer_id not in recommendations:\n",
    "            continue\n",
    "        \n",
    "        # Get the recommendations for this movie\n",
    "        movie_recs = recommendations[trailer_id]\n",
    "        rec_movie_ids = []\n",
    "        \n",
    "        # Convert trailer IDs in recommendations to movie IDs\n",
    "        for rec in movie_recs:\n",
    "            rec_trailer_id = rec['trailer_id']\n",
    "            if rec_trailer_id in trailer_to_movie:\n",
    "                rec_movie_id = trailer_to_movie[rec_trailer_id]\n",
    "                rec_movie_ids.append(rec_movie_id)\n",
    "        \n",
    "        # Find users who have rated this movie positively\n",
    "        relevant_users = []\n",
    "        for user_id, relevant_items in user_items.items():\n",
    "            if movie_id in relevant_items:\n",
    "                relevant_users.append(user_id)\n",
    "        \n",
    "        # Skip if no users rated this movie positively\n",
    "        if not relevant_users:\n",
    "            continue\n",
    "        \n",
    "        # For each relevant user, evaluate the recommendations\n",
    "        item_metrics = {\n",
    "            'precision': {k: 0.0 for k in k_values},\n",
    "            'recall': {k: 0.0 for k in k_values},\n",
    "            'hit_rate': {k: 0.0 for k in k_values},\n",
    "            'ndcg': {k: 0.0 for k in k_values},\n",
    "            'MRR': {k: 0.0 for k in k_values}\n",
    "\n",
    "        }\n",
    "        \n",
    "        valid_users = 0\n",
    "        for user_id in relevant_users:\n",
    "            # Get the set of other movies this user rated positively\n",
    "            other_relevant_items = user_items[user_id] - {movie_id}\n",
    "            \n",
    "            # Skip if user has no other relevant items\n",
    "            if not other_relevant_items:\n",
    "                continue\n",
    "            \n",
    "            # Get all ratings from this user\n",
    "            user_ratings = user_item_ratings[user_id]\n",
    "            \n",
    "            valid_users += 1\n",
    "            \n",
    "            # Calculate metrics for each k\n",
    "            for k in k_values:\n",
    "                item_metrics['precision'][k] += precision_at_k(rec_movie_ids, other_relevant_items, k)\n",
    "                item_metrics['recall'][k] += recall_at_k(rec_movie_ids, other_relevant_items, k)\n",
    "                item_metrics['hit_rate'][k] += hit_rate_at_k(rec_movie_ids, other_relevant_items, k)\n",
    "                item_metrics['ndcg'][k] += ndcg_at_k(rec_movie_ids, user_ratings, k)\n",
    "                item_metrics['MRR'][k] += mean_reciprocal_rank(rec_movie_ids, other_relevant_items, k)\n",
    "        \n",
    "        # Average metrics for this item\n",
    "        if valid_users > 0:\n",
    "            for metric in item_metrics:\n",
    "                for k in k_values:\n",
    "                    item_metrics[metric][k] /= valid_users\n",
    "            \n",
    "            # Add to overall metrics\n",
    "            for metric in metrics:\n",
    "                for k in k_values:\n",
    "                    metrics[metric][k] += item_metrics[metric][k]\n",
    "            \n",
    "            evaluated_items += 1\n",
    "    \n",
    "    # Average metrics across all evaluated items\n",
    "    if evaluated_items > 0:\n",
    "        for metric in metrics:\n",
    "            for k in k_values:\n",
    "                metrics[metric][k] /= evaluated_items\n",
    "    \n",
    "    print(f\"Evaluated {evaluated_items} valid items\")\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c167f200",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "901ae78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_user_data(s3_client: Any, bucket: str, user_items_key: str, user_ratings_key: str, ratings_df: pd.DataFrame) -> Tuple[Dict, Dict]:\n",
    "    \"\"\"\n",
    "    Checks if pre-processed user data exists on S3 and loads it.\n",
    "    If not, it processes the data, saves it to S3, and then returns it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if BOTH files exist by trying to get their metadata\n",
    "        s3_client.head_object(Bucket=bucket, Key=user_items_key)\n",
    "        s3_client.head_object(Bucket=bucket, Key=user_ratings_key)\n",
    "\n",
    "        print(\"✅ Cache hit! Loading pre-processed user data from S3...\")\n",
    "        user_items = load_data_from_s3(bucket, user_items_key)\n",
    "        user_item_ratings = load_data_from_s3(bucket, user_ratings_key)\n",
    "        print(\"Pre-processed user data loaded successfully.\")\n",
    "        \n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        # If the error is 404 (Not Found), the files don't exist\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            print(\"⚠️ Cache miss! Pre-processed data not found on S3.\")\n",
    "            print(\"Processing user-item data now (this may take over 20 minutes)...\")\n",
    "            \n",
    "            # Run the original, slow function\n",
    "            user_items, user_item_ratings = prepare_user_item_data(ratings_df)\n",
    "            \n",
    "            print(\"Saving processed data to S3 cache for future runs...\")\n",
    "            # Save the results to S3 for next time\n",
    "            save_data_to_s3(user_items, bucket, user_items_key)\n",
    "            save_data_to_s3(user_item_ratings, bucket, user_ratings_key)\n",
    "            \n",
    "        else:\n",
    "            # If it's another error (e.g., permissions), raise it\n",
    "            print(\"An unexpected S3 error occurred.\")\n",
    "            raise e\n",
    "            \n",
    "    return user_items, user_item_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07c3dd63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # --- 1. Global Setup\n",
    "    S3_BUCKET_NAME = \"md-data-content-recommendation\"\n",
    "    RATINGS_BENCHMARK_KEY = 'evaluation/ratings_13919_filtered.csv'\n",
    "    K_VALUES = [1, 3, 5, 10]\n",
    "\n",
    "    OUTPUT_BASE_DIR = \"comparison_evaluation/\"\n",
    "    \n",
    "    USER_ITEMS_CACHE_KEY = f\"{OUTPUT_BASE_DIR}cache/user_items_13919.pkl\"\n",
    "    USER_RATINGS_CACHE_KEY = f\"{OUTPUT_BASE_DIR}cache/user_item_ratings_13919.pkl\"\n",
    "    PARTIAL_RESULTS_PREFIX = f\"{OUTPUT_BASE_DIR}partial_results/\"\n",
    "    \n",
    "    pipeline_names = [\"E2E_Pair_Cosine\", \"E2E_Pair_Euclidean\", \"E2E_Triplet_Cosine\", \"E2E_Triplet_Euclidean\"]\n",
    "    baseline_pipelines = {\n",
    "        \"Baseline_FS_Elbow\": \"FS_similarity_and_recommendations/elbowrecommendations_top_10.pkl\",\n",
    "        \"Baseline_All_Features\": \"similarity_and_recommendations/recommendations_top_10.pkl\"\n",
    "    }\n",
    "    \n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    # --- 2. Load Global Data Once\n",
    "    print(\"--- Preparing Global Evaluation Data ---\\n\")\n",
    "    ratings_df_global = load_data_from_s3(S3_BUCKET_NAME, RATINGS_BENCHMARK_KEY)\n",
    "    ratings_df_global[\"movieId\"] = ratings_df_global[\"movieId\"].astype(str)\n",
    "    \n",
    "    user_items, user_item_ratings = get_or_create_user_data(\n",
    "        s3_client,\n",
    "        S3_BUCKET_NAME,\n",
    "        USER_ITEMS_CACHE_KEY,\n",
    "        USER_RATINGS_CACHE_KEY,\n",
    "        ratings_df_global.copy()\n",
    "    )\n",
    "\n",
    "    all_pipelines_history = []\n",
    "    \n",
    "    # --- 3. Loop Through Each E2E Pipeline \n",
    "    for name in pipeline_names:\n",
    "        print(f\"\\n{'='*50}\\nEvaluating all epochs for: {name}\\n{'='*50}\")\n",
    "        \n",
    "        rec_prefix = f\"evaluation/per_epoch_recs/{name}/\"\n",
    "        response = s3_client.list_objects_v2(Bucket=S3_BUCKET_NAME, Prefix=rec_prefix)\n",
    "        all_pkl_files = [obj['Key'] for obj in response.get('Contents', []) if obj['Key'].endswith('.pkl')]\n",
    "        rec_files = [f for f in all_pkl_files if re.search(r'epoch_(\\d+)', f)]\n",
    "        \n",
    "        if not rec_files:\n",
    "            print(f\"WARNING: No files with epoch numbers found for pipeline '{name}'. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        rec_files.sort(key=lambda x: int(re.search(r'epoch_(\\d+)', x).group(1)))\n",
    "        \n",
    "        for rec_key in tqdm(rec_files, desc=f\"Evaluating {name} recs\"):\n",
    "            epoch_num = int(re.search(r'epoch_(\\d+)', rec_key).group(1))\n",
    "            \n",
    "            partial_result_key = f\"{PARTIAL_RESULTS_PREFIX}{name}_epoch_{epoch_num}.pkl\"\n",
    "            try:\n",
    "                s3_client.head_object(Bucket=S3_BUCKET_NAME, Key=partial_result_key)\n",
    "                print(f\"✅ Found existing result for {name} epoch {epoch_num}. Skipping calculation.\")\n",
    "                flat_metrics = load_data_from_s3(S3_BUCKET_NAME, partial_result_key)\n",
    "                all_pipelines_history.append(flat_metrics)\n",
    "                continue # Skip to the next epoch\n",
    "            except botocore.exceptions.ClientError as e:\n",
    "                if e.response['Error']['Code'] != '404':\n",
    "                    raise\n",
    "            \n",
    "            print(f\"Calculating metrics for {name} epoch {epoch_num}...\")\n",
    "            recommendations = load_data_from_s3(S3_BUCKET_NAME, rec_key)\n",
    "            trailer_to_movie, _ = build_improved_trailer_to_movie_mapping(recommendations, ratings_df_global)\n",
    "            metrics = item_based_evaluation(recommendations, user_items, user_item_ratings, trailer_to_movie, K_VALUES)\n",
    "            \n",
    "            flat_metrics = {'model': name, 'epoch': epoch_num}\n",
    "            for metric, values in metrics.items():\n",
    "                for k, value in values.items():\n",
    "                    flat_metrics[f\"{metric}@{k}\"] = value\n",
    "            all_pipelines_history.append(flat_metrics)\n",
    "\n",
    "            print(f\"Saving checkpoint for {name} epoch {epoch_num}...\")\n",
    "            save_data_to_s3(flat_metrics, S3_BUCKET_NAME, partial_result_key)\n",
    "\n",
    "\n",
    "    # --- 4. Evaluate the Baseline Models\n",
    "    for name, rec_key in baseline_pipelines.items():\n",
    "        print(f\"\\n{'='*50}\\nEvaluating Baseline: {name}\\n{'='*50}\")\n",
    "        \n",
    "        partial_result_key = f\"{PARTIAL_RESULTS_PREFIX}{name}_baseline.pkl\"\n",
    "        try:\n",
    "            s3_client.head_object(Bucket=S3_BUCKET_NAME, Key=partial_result_key)\n",
    "            print(f\"Found existing result for baseline {name}. Skipping calculation.\")\n",
    "            flat_metrics = load_data_from_s3(S3_BUCKET_NAME, partial_result_key)\n",
    "            all_pipelines_history.append(flat_metrics)\n",
    "            continue\n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            if e.response['Error']['Code'] != '404': raise\n",
    "\n",
    "        print(f\"Calculating metrics for baseline {name}...\")\n",
    "        recommendations = load_data_from_s3(S3_BUCKET_NAME, rec_key)\n",
    "        trailer_to_movie, _ = build_improved_trailer_to_movie_mapping(recommendations, ratings_df_global)\n",
    "        metrics = item_based_evaluation(recommendations, user_items, user_item_ratings, trailer_to_movie, K_VALUES)\n",
    "        \n",
    "        flat_metrics = {'model': name, 'epoch': -1}\n",
    "        for metric, values in metrics.items():\n",
    "            for k, value in values.items():\n",
    "                flat_metrics[f\"{metric}@{k}\"] = value\n",
    "        all_pipelines_history.append(flat_metrics)\n",
    "        \n",
    "        print(f\"Saving checkpoint for baseline {name}...\")\n",
    "        save_data_to_s3(flat_metrics, S3_BUCKET_NAME, partial_result_key)\n",
    "\n",
    "\n",
    "    # --- 5. Create and Save the Final DataFrame\n",
    "    final_results_df = pd.DataFrame(all_pipelines_history)\n",
    "    print(\"\\n--- Full Evaluation History ---\")\n",
    "    print(final_results_df.head())\n",
    "    \n",
    "    final_output_key = f\"{OUTPUT_BASE_DIR}final_all_models_per_epoch_results.csv\"\n",
    "    save_data_to_s3(final_results_df, S3_BUCKET_NAME, final_output_key)\n",
    "    print(f\"Final aggregated results saved to s3://{S3_BUCKET_NAME}/{final_output_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b9ea3",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a821328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the final results we just created ---\n",
    "results_df = load_data_from_s3(S3_BUCKET_NAME, FINAL_RESULTS_KEY)\n",
    "\n",
    "# Convert epoch to numeric. Baselines have epoch -1.\n",
    "results_df['epoch'] = pd.to_numeric(results_df['epoch'])\n",
    "\n",
    "# Separate E2E models from baselines for plotting\n",
    "e2e_df = results_df[results_df['epoch'] != -1].copy()\n",
    "baseline_df = results_df[results_df['epoch'] == -1].copy()\n",
    "\n",
    "def plot_metric_evolution(df_e2e, df_baseline, metrics_to_plot, primary_metric='ndcg@10'):\n",
    "    num_metrics = len(metrics_to_plot)\n",
    "    ncols = 2\n",
    "    nrows = (num_metrics + ncols - 1) // ncols\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 8, nrows * 6), sharex=False)\n",
    "    axes = axes.flatten()\n",
    "    model_names = df_e2e['model'].unique()\n",
    "    palette = sns.color_palette(\"husl\", len(model_names))\n",
    "    model_color_map = dict(zip(model_names, palette))\n",
    "\n",
    "    # --- Find the best epoch for each model based on the primary metric ---\n",
    "    best_epoch_indices = df_e2e.loc[df_e2e.groupby('model')[primary_metric].idxmax()]\n",
    "    \n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Plot the E2E models' evolution over time\n",
    "        sns.lineplot(data=df_e2e, x='epoch', y=metric, hue='model', palette=palette, marker='o', alpha=0.8, ax=ax)\n",
    "        \n",
    "        # Plot baselines as horizontal dashed lines\n",
    "        for _, row in df_baseline.iterrows():\n",
    "            ax.axhline(y=row.get(metric, 0), linestyle='--', label=f\"{row['model']} (Baseline)\", color='gray', alpha=0.9)\n",
    "\n",
    "        # Highlight the best epoch for each model with a star\n",
    "        for model_name in model_names:\n",
    "            best_epoch_row = best_epoch_indices[best_epoch_indices['model'] == model_name]\n",
    "            if not best_epoch_row.empty:\n",
    "                best_epoch_num = best_epoch_row['epoch'].iloc[0]\n",
    "                # Get the metric value at that specific best epoch\n",
    "                metric_val_at_best_epoch = df_e2e[(df_e2e['model'] == model_name) & (df_e2e['epoch'] == best_epoch_num)][metric].iloc[0]\n",
    "                \n",
    "                ax.scatter(best_epoch_num, metric_val_at_best_epoch, \n",
    "                           marker='*', s=350, color=model_color_map[model_name], \n",
    "                           edgecolor='black', zorder=10, \n",
    "                           label=f'Best {model_name} (Epoch {int(best_epoch_num)})')\n",
    "\n",
    "        ax.set_title(f'Evolution of {metric}', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel(metric)\n",
    "        ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        \n",
    "        # Improve legend\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        # Custom filtering to avoid duplicate labels from scatter\n",
    "        unique_labels = dict(zip(labels, handles))\n",
    "        ax.legend(unique_labels.values(), unique_labels.keys(), title='Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(num_metrics, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "        \n",
    "    fig.suptitle(f'Comparison of E2E Model Performance (Best Epoch by {primary_metric})', fontsize=18, fontweight='bold')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# --- Call the plotting function ---\n",
    "key_metrics_to_plot = ['ndcg@10', 'hit_rate@10', 'precision@10', 'MRR@10']\n",
    "plot_metric_evolution(e2e_df, baseline_df, key_metrics_to_plot)\n",
    "\n",
    "# --- Display Final Summary Table ---\n",
    "print(\"\\n--- Final Performance Table (Best Epoch vs. Baselines) ---\")\n",
    "# Find the best performing epoch for each E2E model\n",
    "best_e2e_df = e2e_df.loc[e2e_df.groupby('model')['ndcg@10'].idxmax()]\n",
    "# Combine with baselines\n",
    "final_table_df = pd.concat([baseline_df, best_e2e_df]).set_index('model')\n",
    "print(final_table_df[[col for col in final_table_df.columns if '@' in col or col == 'epoch']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
